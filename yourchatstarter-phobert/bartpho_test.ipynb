{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bartpho_test.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyN1DGLv06/5kTutihMi6u6P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"348a44b647b24c0fa91b7b559d5fcf41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_850567d851e54107ad833f794566e86d","IPY_MODEL_5621fb4ec30e4b279ed70b2264618319","IPY_MODEL_e8dce597469e41dcb5342f82f2d74e9f"],"layout":"IPY_MODEL_8a3539cae741469b81e13484db6fe3a9"}},"850567d851e54107ad833f794566e86d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac66ce9163fe41e6a56a59783bf85417","placeholder":"​","style":"IPY_MODEL_7ccbc4e1048049a982ad2081fbb9c71d","value":"Downloading: 100%"}},"5621fb4ec30e4b279ed70b2264618319":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4741c514d80e4f4dbcd66f409953a26a","max":866,"min":0,"orientation":"horizontal","style":"IPY_MODEL_940936134cf04814b642472b3e5a56a7","value":866}},"e8dce597469e41dcb5342f82f2d74e9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0379856a81c34e83930ef5513dad6efc","placeholder":"​","style":"IPY_MODEL_93c1cb1c10a649c5b1f32e0baa38dfc1","value":" 866/866 [00:00&lt;00:00, 20.5kB/s]"}},"8a3539cae741469b81e13484db6fe3a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac66ce9163fe41e6a56a59783bf85417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ccbc4e1048049a982ad2081fbb9c71d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4741c514d80e4f4dbcd66f409953a26a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"940936134cf04814b642472b3e5a56a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0379856a81c34e83930ef5513dad6efc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93c1cb1c10a649c5b1f32e0baa38dfc1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e221bf8340f4e3bb96074255bd23fd7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_facd839d498a45e3829696f81dab361c","IPY_MODEL_d58d527c04cb4e2a8866ef1588984762","IPY_MODEL_c9a569b4f1c7477295fc2ead1523afe6"],"layout":"IPY_MODEL_62aebce1012b4f28bff861c9547c6462"}},"facd839d498a45e3829696f81dab361c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25cb25639eef427e9175b97c4ab71512","placeholder":"​","style":"IPY_MODEL_e544c01de39647fdac062d753e88dcfe","value":"Downloading: 100%"}},"d58d527c04cb4e2a8866ef1588984762":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae2a45851cfa4d078ff4cb9fa88c3f28","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11c9884b55b647bb8745918df0c5f222","value":895321}},"c9a569b4f1c7477295fc2ead1523afe6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d30fad80b3e48f3b1c4705249213dff","placeholder":"​","style":"IPY_MODEL_88c2f5db15504b80af7d5242f32b1586","value":" 874k/874k [00:01&lt;00:00, 945kB/s]"}},"62aebce1012b4f28bff861c9547c6462":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25cb25639eef427e9175b97c4ab71512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e544c01de39647fdac062d753e88dcfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae2a45851cfa4d078ff4cb9fa88c3f28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11c9884b55b647bb8745918df0c5f222":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d30fad80b3e48f3b1c4705249213dff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88c2f5db15504b80af7d5242f32b1586":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6e43f1dd8ed4e0d8f717591dff9f7c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd2914801f33473ca568c2ed445db540","IPY_MODEL_cb9b4d8ec9f547aba6f61501e9b2d5cb","IPY_MODEL_42b7f76ede48412abbb1eb491d7a9306"],"layout":"IPY_MODEL_e61fc31d4bce4095a612ada5fabf0c9a"}},"bd2914801f33473ca568c2ed445db540":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1080fafc9b404eafa782fae6d66452e4","placeholder":"​","style":"IPY_MODEL_0f0830a58dc045aaaa614ee235bee990","value":"Downloading: 100%"}},"cb9b4d8ec9f547aba6f61501e9b2d5cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf396a85f88747c18be454d073fa09de","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2dd5a447fc5648f2a5f8e4e55c00a15c","value":1135173}},"42b7f76ede48412abbb1eb491d7a9306":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_818f7d9bd84a44f1a589120d96d1ed06","placeholder":"​","style":"IPY_MODEL_a134122154c04b39a4119b21948b5acb","value":" 1.08M/1.08M [00:01&lt;00:00, 1.04MB/s]"}},"e61fc31d4bce4095a612ada5fabf0c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1080fafc9b404eafa782fae6d66452e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f0830a58dc045aaaa614ee235bee990":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf396a85f88747c18be454d073fa09de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dd5a447fc5648f2a5f8e4e55c00a15c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"818f7d9bd84a44f1a589120d96d1ed06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a134122154c04b39a4119b21948b5acb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee2aec8d669d41ef87e5b1212ec04a7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ccbcb3ef1a9b4969bed760bb848df6e0","IPY_MODEL_698708b94aef4b00823cbe428b03de7d","IPY_MODEL_bfcc107db0164138a89829233c6acdbe"],"layout":"IPY_MODEL_e2b3797a0c1948f492d626574280211f"}},"ccbcb3ef1a9b4969bed760bb848df6e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a29228a195b4e34be894e01aba06403","placeholder":"​","style":"IPY_MODEL_389149d58e7749ecbd77888eefcee705","value":"Downloading: 100%"}},"698708b94aef4b00823cbe428b03de7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea31666c54ae449a819a4df6e5164c50","max":1681637133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f8e2e0921724c5594f4d68172e124af","value":1681637133}},"bfcc107db0164138a89829233c6acdbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b32494e8fdd84c059ceae3fcceaead54","placeholder":"​","style":"IPY_MODEL_f80aaecc382d4563bcda25604a1133d9","value":" 1.57G/1.57G [00:26&lt;00:00, 66.5MB/s]"}},"e2b3797a0c1948f492d626574280211f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a29228a195b4e34be894e01aba06403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"389149d58e7749ecbd77888eefcee705":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea31666c54ae449a819a4df6e5164c50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f8e2e0921724c5594f4d68172e124af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b32494e8fdd84c059ceae3fcceaead54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f80aaecc382d4563bcda25604a1133d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["pip install galore (Your boring dependency installation)"],"metadata":{"id":"Y4yfNAUUqFhf"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7WNGRXNPr46","executionInfo":{"status":"ok","timestamp":1653202766773,"user_tz":-420,"elapsed":24695,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"089ad5ce-adc0-4230-fe17-6780ab08dd06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 34.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=74ee8b6433c6ea7b66a52b838d81f5df6154eeea91a8266692c734ed4cdf2c3a\n","  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 27.5 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 78.3 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 80.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 36.8 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.6.3-py3-none-any.whl (584 kB)\n","\u001b[K     |████████████████████████████████| 584 kB 30.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.2.0)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Collecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n","\u001b[K     |████████████████████████████████| 409 kB 20.8 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 97.2 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.7)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.46.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 59.4 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 2.2 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 13.9 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, pytorch-lightning\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.3 torchmetrics-0.8.2 yarl-1.7.2\n"]}],"source":["!pip3 install vncorenlp\n","!pip3 install transformers\n","!pip3 install sentencepiece\n","!pip3 install pytorch-lightning"]},{"cell_type":"markdown","source":["Download VNCoreNLP (word segmenter feature only)"],"metadata":{"id":"nNkauWyCqN4S"}},{"cell_type":"code","source":["!mkdir -p VnCoreNLP/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv VnCoreNLP-1.1.1.jar VnCoreNLP/ \n","!mv vi-vocab VnCoreNLP/models/wordsegmenter/\n","!mv wordsegmenter.rdr VnCoreNLP/models/wordsegmenter/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRM6ojaMQSvG","executionInfo":{"status":"ok","timestamp":1653202787377,"user_tz":-420,"elapsed":35,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"9d8deeb9-9b00-4dbc-f20b-c432a9162d86"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-22 06:59:42--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27412575 (26M) [application/octet-stream]\n","Saving to: ‘VnCoreNLP-1.1.1.jar’\n","\n","VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  --.-KB/s    in 0.1s    \n","\n","2022-05-22 06:59:42 (246 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n","\n","--2022-05-22 06:59:42--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 526544 (514K) [application/octet-stream]\n","Saving to: ‘vi-vocab’\n","\n","vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.005s  \n","\n","2022-05-22 06:59:43 (110 MB/s) - ‘vi-vocab’ saved [526544/526544]\n","\n","--2022-05-22 06:59:43--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 128508 (125K) [text/plain]\n","Saving to: ‘wordsegmenter.rdr’\n","\n","wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.002s  \n","\n","2022-05-22 06:59:43 (52.3 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n","\n"]}]},{"cell_type":"markdown","source":["Mount my Google Drive to this machine (To load training data and save/load checkpoint)"],"metadata":{"id":"1qQxXO5Bqhue"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=False)\n","root_dir = \"/content/gdrive/MyDrive/\"\n","base_dir = root_dir + 'ElainaModel/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQDE30IytSlR","executionInfo":{"status":"ok","timestamp":1653202850736,"user_tz":-420,"elapsed":52677,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"73c0161c-176e-44a5-b3bb-dc0b1dd0d5de"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["Now the fun bit (Setting up the model as a PyTorch Lightning model)"],"metadata":{"id":"B-3zaukLqwW9"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModel, AutoTokenizer\n","from transformers import MBartForConditionalGeneration, AdamW, BartConfig, BartTokenizer, MBartTokenizer\n","from vncorenlp import VnCoreNLP\n","\n","from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n","import pandas as pd\n","import numpy as np\n","\n","import torch.nn.functional as F\n","import pytorch_lightning as lightning\n","import torch\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","import math\n","import random\n","import re\n","import argparse\n","\n","class ElainaModel(lightning.LightningModule):\n","    def __init__(self, learning_rate, tokenizer, model, hparams):\n","      super().__init__()\n","      self.tokenizer = tokenizer\n","      self.model = model\n","      self.learning_rate = learning_rate\n","      # self.freeze_encoder = freeze_encoder\n","      # self.freeze_embeds_ = freeze_embeds\n","      self.hparams.update(hparams)\n","\n","      if self.hparams.freeze_encoder:\n","        freeze_params(self.model.get_encoder())\n","\n","      if self.hparams.freeze_embeds:\n","        self.freeze_embeds()\n","\n","      print('constructor end')\n","    \n","    def freeze_embeds(self):\n","      ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n","      freeze_params(self.model.model.shared)\n","      for d in [self.model.model.encoder, self.model.model.decoder]:\n","        freeze_params(d.embed_positions)\n","        freeze_params(d.embed_tokens)\n","\n","    # Do a forward pass through the model\n","    def forward(self, input_ids, **kwargs):\n","      return self.model(input_ids, **kwargs)\n","    \n","    def configure_optimizers(self):\n","      optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n","      return optimizer\n","\n","    def training_step(self, batch, batch_idx):\n","      # Load the data into variables\n","      src_ids, src_mask = batch[0], batch[1]\n","      tgt_ids = batch[2]\n","      # Shift the decoder tokens right (but NOT the tgt_ids)\n","      # replaced tokenizer with self.tokenizer\n","      decoder_input_ids = shift_tokens_right(tgt_ids, self.tokenizer.pad_token_id)\n","\n","      # Run the model and get the logits\n","      outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n","      lm_logits = outputs[0]\n","      # Create the loss function\n","      ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n","      # Calculate the loss on the un-shifted tokens\n","      loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n","\n","      return {'loss':loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","\n","      src_ids, src_mask = batch[0], batch[1]\n","      tgt_ids = batch[2]\n","\n","      # replaced tokenizer with self.tokenizer\n","      decoder_input_ids = shift_tokens_right(tgt_ids, self.tokenizer.pad_token_id)\n","      \n","      # Run the model and get the logits\n","      outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n","      lm_logits = outputs[0]\n","\n","      ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n","      val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n","\n","      return {'loss': val_loss}\n","    \n","    # Method that generates text using the BartForConditionalGeneration's generate() method\n","    def generate_text(self, text, eval_beams, early_stopping = True, max_len = 40):\n","      ''' Function to generate text '''\n","      generated_ids = self.model.generate(\n","          text[\"input_ids\"],\n","          attention_mask=text[\"attention_mask\"],\n","          use_cache=True,\n","          decoder_start_token_id = self.tokenizer.pad_token_id,\n","          num_beams= eval_beams,\n","          max_length = max_len,\n","          early_stopping = early_stopping\n","      )\n","      return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n","\n","def freeze_params(model):\n","  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n","      adapted from finetune.py '''\n","  for layer in model.parameters():\n","    layer.requires_grade = False\n","\n","def shift_tokens_right(input_ids, pad_token_id):\n","  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n","      This is taken directly from modeling_bart.py\n","  \"\"\"\n","  prev_output_tokens = input_ids.clone()\n","  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n","  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n","  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n","  return prev_output_tokens\n","\n"],"metadata":{"id":"k0-10-AGQlke","executionInfo":{"status":"ok","timestamp":1653202862831,"user_tz":-420,"elapsed":5137,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Sentence enconding function to turn all text things into number things (using BART's tokenizer)"],"metadata":{"id":"D8N-d7Ndq9U5"}},{"cell_type":"code","source":["def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=32, pad_to_max_length=True, return_tensors=\"pt\", rdrsegmenter=None):\n","  ''' Function that tokenizes a sentence \n","      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n","      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n","  '''\n","\n","  input_ids = []\n","  attention_masks = []\n","  target_ids = []\n","  tokenized_sentences = {}\n","\n","  for sentence in source_sentences:\n","    if rdrsegmenter is not None:\n","      seg_sentence = rdrsegmenter.tokenize(sentence)\n","      seg_sentence = ' '.join([' '.join(x) for x in seg_sentence])\n","    else:\n","      seg_sentence = sentence\n","    encoded_dict = tokenizer(\n","          seg_sentence,\n","          max_length=max_length,\n","          padding=\"max_length\" if pad_to_max_length else None,\n","          truncation=True,\n","          return_tensors=return_tensors,\n","          # add_prefix_space = True\n","      )\n","\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","  input_ids = torch.cat(input_ids, dim = 0)\n","  attention_masks = torch.cat(attention_masks, dim = 0)\n","\n","  for sentence in target_sentences:\n","    if rdrsegmenter is not None:\n","      seg_sentence = rdrsegmenter.tokenize(sentence)\n","      seg_sentence = ' '.join([' '.join(x) for x in seg_sentence])\n","    else:\n","      seg_sentence = sentence\n","    encoded_dict = tokenizer(\n","          seg_sentence,\n","          max_length=max_length,\n","          padding=\"max_length\" if pad_to_max_length else None,\n","          truncation=True,\n","          return_tensors=return_tensors,\n","          # add_prefix_space = True\n","      )\n","    # Shift the target ids to the right\n","    # shifted_target_ids = shift_tokens_right(encoded_dict['input_ids'], tokenizer.pad_token_id)\n","    target_ids.append(encoded_dict['input_ids'])\n","\n","  target_ids = torch.cat(target_ids, dim = 0)\n","  \n","\n","  batch = {\n","      \"input_ids\": input_ids,\n","      \"attention_mask\": attention_masks,\n","      \"labels\": target_ids,\n","  }\n","\n","  return batch"],"metadata":{"id":"slBB7YsQtxhn","executionInfo":{"status":"ok","timestamp":1653202867411,"user_tz":-420,"elapsed":1009,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Data loading class where we get the .csv file and (after the totally optional word segmenting task) get encoded into tensors (lots of'em)"],"metadata":{"id":"Z4crNYqQrMz_"}},{"cell_type":"code","source":["# Create a dataloading module as per the PyTorch Lightning Docs\n","class SummaryDataModule(lightning.LightningDataModule):\n","  def __init__(self, tokenizer, data_file, batch_size, num_examples = 20000, use_segmenter = False):\n","    super().__init__()\n","    self.tokenizer = tokenizer\n","    self.data_file = data_file\n","    self.batch_size = batch_size\n","    self.num_examples = num_examples\n","\n","    if use_segmenter:\n","      self.rdrsegmenter = VnCoreNLP(\"./VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n","    else:\n","      self.rdrsegmenter = None\n","  \n","  # Loads and splits the data into training, validation and test sets with a 60/20/20 split\n","  def prepare_data(self):\n","    self.data = pd.read_csv(self.data_file)[:self.num_examples]\n","    self.train, self.validate, self.test = np.split(self.data.sample(frac=1), [int(.6*len(self.data)), int(.8*len(self.data))])\n","\n","  # encode the sentences using the tokenizer  \n","  def setup(self, stage):\n","    self.train = encode_sentences(self.tokenizer, self.train['source'], self.train['target'], rdrsegmenter = self.rdrsegmenter)\n","    self.validate = encode_sentences(self.tokenizer, self.validate['source'], self.validate['target'], rdrsegmenter = self.rdrsegmenter)\n","    self.test = encode_sentences(self.tokenizer, self.test['source'], self.test['target'], rdrsegmenter = self.rdrsegmenter)\n","\n","  # Load the training, validation and test sets in Pytorch Dataset objects\n","  def train_dataloader(self):\n","    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])                          \n","    train_data = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n","    return train_data\n","\n","  def val_dataloader(self):\n","    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels']) \n","    val_data = DataLoader(dataset, batch_size = self.batch_size)                       \n","    return val_data\n","\n","  def test_dataloader(self):\n","    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels']) \n","    test_data = DataLoader(dataset, batch_size = self.batch_size)                   \n","    return test_data\n"],"metadata":{"id":"-ak7y14DSA9x","executionInfo":{"status":"ok","timestamp":1653202871400,"user_tz":-420,"elapsed":4,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["The part where we can acually use our model which include the noise generator for less predictable behavior and the generation function"],"metadata":{"id":"5jJjuDKlrmRU"}},{"cell_type":"code","source":["\n","def noise_sentence(sentence_, percent_words, replacement_token = \"<mask>\"):\n","  '''\n","  Function that noises a sentence by adding <mask> tokens\n","  Args: sentence - the sentence to noise\n","        percent_words - the percent of words to replace with <mask> tokens; the number is rounded up using math.ceil\n","  Returns a noised sentence\n","  '''\n","  # Create a list item and copy\n","  sentence_ = sentence_.split(' ')\n","  sentence = sentence_.copy()\n","  \n","  num_words = math.ceil(len(sentence) * percent_words)\n","  \n","  # Create an array of tokens to sample from; don't include the last word as an option because in the case of lyrics\n","  # that word is often a rhyming word and plays an important role in song construction\n","  sample_tokens = set(np.arange(0, np.maximum(1, len(sentence)-1)))\n","  \n","  words_to_noise = random.sample(sample_tokens, num_words)\n","  \n","  # Swap out words, but not full stops\n","  for pos in words_to_noise:\n","      if sentence[pos] != '.':\n","          sentence[pos] = replacement_token\n","  \n","  # Remove redundant spaces\n","  sentence = re.sub(r' {2,5}', ' ', ' '.join(sentence))\n","  \n","  # Combine concurrent <mask> tokens into a single token; this just does two rounds of this; more could be done\n","  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n","  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n","  return sentence\n","\n","def generate_response(seed_line, num_lines, model_, noise_percent = 0.25, multiple_lines = False, max_line_history = 3, rdrsegmenter = None):\n","  ''' Function that generates lyrics based on previously generated lyrics \n","      Args: seed_line - a line to start off the machine\n","            num_lines - the number of lines to generate\n","            model_ - the model used to generate the text\n","            multiple_lines - whether the model generates based on multiple previous lines or just the past line\n","            max_line_history - the maximum number of previous lines used in the current input\n","      Returns a list with num_lines of rap lines\n","  '''\n","  # Put the model on eval mode\n","  model_.to(torch.device('cpu'))\n","  model_.eval()\n","  if rdrsegmenter is not None:\n","    seed_line = ' '.join([' '.join(x) for x in rdrsegmenter.tokenize(seed_line)])\n","  dialog = []\n","  dialog.append(seed_line)\n","  # not using noise gen here, lets see if it works\n","  prompt_line_tokens = tokenizer(noise_sentence(seed_line, 0.2), max_length = 32, return_tensors = \"pt\", truncation = True)\n","  # Loop through the number of lines generating a new line based on the old\n","\n","  line = [seed_line]\n","  for i in range(num_lines):\n","    # Print out the new line\n","    entry = line[0].strip().replace('< s >', '').replace('< / s >', '')\n","    # print(entry)\n","    dialog.append(entry)\n","    line = model.generate_text(prompt_line_tokens, eval_beams = 4)\n","    # This deals with an artefact in the training data that I had an issue cleaning\n","    if line[0].find(\":\") != -1:\n","      line[0] = re.sub(r'[A-Z]+: ', '', line[0])\n","    # This allows the model to generate a new line conditioned on more than one line\n","    if multiple_lines:\n","      start_line = np.maximum(0, i - max_line_history)\n","      end_line = i\n","      prompt_line = ' '.join(dialog[start_line:end_line]) # Going to end_line is fine because it is non-inclusive\n","    else:\n","      prompt_line = dialog[i]\n","    # not using noise gen here, lets see if it works\n","    prompt_line_tokens = tokenizer(noise_sentence(prompt_line, 0.2), max_length = 32, return_tensors = \"pt\", truncation = True)\n","\n","  return dialog"],"metadata":{"id":"9SDp_ym2FAx_","executionInfo":{"status":"ok","timestamp":1653204047068,"user_tz":-420,"elapsed":3,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["This is the main function, we first setup our tokenizer and base BARTPho model"],"metadata":{"id":"qElo_gdAsLuL"}},{"cell_type":"code","source":["hparams = {\n","    'freeze_encoder': True,\n","    'freeze_embeds': True,\n","    'eval_beams': 4\n","}\n","\n","print('Setting up tokenizer...')\n","tokenizer = AutoTokenizer.from_pretrained('vinai/bartpho-word')\n","\n","print('Setting up BARTPho pretrained model...')\n","bart_model = MBartForConditionalGeneration.from_pretrained('vinai/bartpho-word')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182,"referenced_widgets":["348a44b647b24c0fa91b7b559d5fcf41","850567d851e54107ad833f794566e86d","5621fb4ec30e4b279ed70b2264618319","e8dce597469e41dcb5342f82f2d74e9f","8a3539cae741469b81e13484db6fe3a9","ac66ce9163fe41e6a56a59783bf85417","7ccbc4e1048049a982ad2081fbb9c71d","4741c514d80e4f4dbcd66f409953a26a","940936134cf04814b642472b3e5a56a7","0379856a81c34e83930ef5513dad6efc","93c1cb1c10a649c5b1f32e0baa38dfc1","2e221bf8340f4e3bb96074255bd23fd7","facd839d498a45e3829696f81dab361c","d58d527c04cb4e2a8866ef1588984762","c9a569b4f1c7477295fc2ead1523afe6","62aebce1012b4f28bff861c9547c6462","25cb25639eef427e9175b97c4ab71512","e544c01de39647fdac062d753e88dcfe","ae2a45851cfa4d078ff4cb9fa88c3f28","11c9884b55b647bb8745918df0c5f222","9d30fad80b3e48f3b1c4705249213dff","88c2f5db15504b80af7d5242f32b1586","c6e43f1dd8ed4e0d8f717591dff9f7c3","bd2914801f33473ca568c2ed445db540","cb9b4d8ec9f547aba6f61501e9b2d5cb","42b7f76ede48412abbb1eb491d7a9306","e61fc31d4bce4095a612ada5fabf0c9a","1080fafc9b404eafa782fae6d66452e4","0f0830a58dc045aaaa614ee235bee990","cf396a85f88747c18be454d073fa09de","2dd5a447fc5648f2a5f8e4e55c00a15c","818f7d9bd84a44f1a589120d96d1ed06","a134122154c04b39a4119b21948b5acb","ee2aec8d669d41ef87e5b1212ec04a7b","ccbcb3ef1a9b4969bed760bb848df6e0","698708b94aef4b00823cbe428b03de7d","bfcc107db0164138a89829233c6acdbe","e2b3797a0c1948f492d626574280211f","4a29228a195b4e34be894e01aba06403","389149d58e7749ecbd77888eefcee705","ea31666c54ae449a819a4df6e5164c50","9f8e2e0921724c5594f4d68172e124af","b32494e8fdd84c059ceae3fcceaead54","f80aaecc382d4563bcda25604a1133d9"]},"id":"9XM9A1RSV8tY","executionInfo":{"status":"ok","timestamp":1653202930902,"user_tz":-420,"elapsed":45243,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"6a0e2fa8-762f-47ae-8c0f-33f361285b76"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/866 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"348a44b647b24c0fa91b7b559d5fcf41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e221bf8340f4e3bb96074255bd23fd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e43f1dd8ed4e0d8f717591dff9f7c3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.57G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee2aec8d669d41ef87e5b1212ec04a7b"}},"metadata":{}}]},{"cell_type":"markdown","source":["Select whether you want to train a new model or use a saved model (once you train a new model, make sure you have a bucket ton of RAM)"],"metadata":{"id":"bpPlHzxPsVEL"}},{"cell_type":"code","source":["do_train = input(\"Bạn muốn huấn luyện mô hình mới hay không? (y/n):\")\n","\n","if do_train == 'y':\n","  print(\"Setting up training / validating data...\")\n","  summary_data = SummaryDataModule(tokenizer, \n","                                  data_file='/content/gdrive/MyDrive/ElainaModel/bart_data.csv',\n","                                  batch_size = 8, num_examples = 800, use_segmenter = True)\n","\n","  print(\"Initializing new model...\")\n","  model = ElainaModel(\n","      learning_rate = 2e-5, \n","      tokenizer = tokenizer, \n","      model = bart_model, \n","      hparams = hparams,\n","  )\n","\n","  checkpoint = ModelCheckpoint(dirpath=base_dir + 'checkpoint_files/')\n","  print(\"Setting up trainer...\")\n","  trainer = lightning.Trainer(\n","      gpus = 1,\n","      max_epochs = 5,\n","      min_epochs = 1,\n","      auto_lr_find = False,\n","      checkpoint_callback = checkpoint,\n","      progress_bar_refresh_rate = 500\n","  )\n","\n","  print(\"Initiate training process.\")\n","  # Prone to Out of Memory error\n","  trainer.fit(model, summary_data)\n","else:\n","  filename = \"checkpoint_files/epoch=4-step=300.ckpt\"\n","\n","  print(\"Loading checkpoint for fine-tuned model\")\n","  model = ElainaModel.load_from_checkpoint(\n","    base_dir + filename, \n","    learning_rate = 2e-5, \n","    tokenizer = tokenizer, \n","    model = bart_model, \n","    hparams = hparams\n","  )"],"metadata":{"id":"NoAKR4ecJeWU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Explained in the comment"],"metadata":{"id":"AuWsiXUHsjYI"}},{"cell_type":"code","source":["# uncomment this line to backup trained checkpoints\n","\n","# !cp lightning_logs/version_0/checkpoints/epoch=4-step=300.ckpt gdrive/MyDrive/ElainaModel/checkpoint_files"],"metadata":{"id":"K9-2isX_DDGF","executionInfo":{"status":"ok","timestamp":1653194402718,"user_tz":-420,"elapsed":36206,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["This is where we can actually test our poor model"],"metadata":{"id":"RvxUBus3sm0j"}},{"cell_type":"code","source":["# testing env\n","\n","rdrsegmenter = VnCoreNLP(\"./VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n","\n","message = \"\"\n","while message != \"exit\":\n","  message = input(\">>> \")\n","  if message == \"exit\": \n","    continue\n","  new_dialog = generate_response(seed_line = message, num_lines = 2, model_ = model,\n","                           noise_percent = 0.2, multiple_lines = False, max_line_history = 1, rdrsegmenter=rdrsegmenter)\n","  print(new_dialog[2].replace(\"_\", \" \"))\n","  \n","print(\"Testing stopped\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrBNCWvSFlr1","executionInfo":{"status":"ok","timestamp":1653204139036,"user_tz":-420,"elapsed":69336,"user":{"displayName":"Dang Nguyen Ngoc","userId":"11023288777081019836"}},"outputId":"546a41ac-3284-4c5a-c06d-02e2b9be9a6e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> chào bạn\n","Hãy nghĩ về tôi như một trợ lý ảo \n",">>> Tại sao?\n"," Tôi có thể được huấn luyện để trở nên hữu dụng hơn. Nhà phát triển sẽ tiếp tục huấn luyện cho tôi. Mong bạn thông cảm \n",">>> Tôi tin tưởng bạn\n","Tôi là trợ lý ảo, không phải người thật. Tôi là trợ lý ảo, không phải người thật \n",">>> Đừng buồn\n","Tôi rất vui. Có thật nhiều điều thú vị ngoài kia \n",">>> exit\n","Testing stopped\n"]}]}]}